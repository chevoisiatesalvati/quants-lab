{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from core.data_sources.clob import CLOBDataSource\n",
    "import warnings\n",
    "\n",
    "from core.notifiers import NotificationManager, NotificationMessage\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Main class to access central limit order book connectors\n",
    "clob = CLOBDataSource()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b87b6281505e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "CONFIG = {\n",
    "    'connector_name': 'binance_perpetual',  # Data source connector (where candles are downloaded from)\n",
    "    'trading_connector': 'bitget_perpetual',  # Trading connector (where we actually trade)\n",
    "    'interval': '1m',\n",
    "    'ema_lengths': [20, 200, 500],\n",
    "    'signal_intensity_threshold': 0.7,\n",
    "    'min_range_pct': 0.01,\n",
    "    'rolling_window': 1000,\n",
    "}\n",
    "\n",
    "def extract_base_token(trading_pair: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the base token from a trading pair.\n",
    "    \n",
    "    Examples:\n",
    "        \"BTC-USDT\" -> \"BTC\"\n",
    "        \"ETH-USD\" -> \"ETH\"\n",
    "        \"BTC/USDT\" -> \"BTC\" (handles both - and / separators)\n",
    "    \"\"\"\n",
    "    # Handle both - and / separators\n",
    "    if '-' in trading_pair:\n",
    "        return trading_pair.split('-')[0]\n",
    "    elif '/' in trading_pair:\n",
    "        return trading_pair.split('/')[0]\n",
    "    else:\n",
    "        # If no separator, return as-is (might be just the token)\n",
    "        return trading_pair\n",
    "\n",
    "# Load candles from cache\n",
    "print(\"ðŸ“¥ Loading candles from cache...\")\n",
    "clob.load_candles_cache()\n",
    "candles = []\n",
    "for key, value in clob.candles_cache.items():\n",
    "    if key[-1] == CONFIG['interval'] and key[0] == CONFIG['connector_name']:\n",
    "        candles.append(value)\n",
    "\n",
    "print(f\"âœ… Loaded {len(candles)} pairs from {CONFIG['connector_name']}\")\n",
    "\n",
    "# Get available trading pairs from the trading connector\n",
    "# Try common quote assets (USD, USDT, etc.) to find what the connector uses\n",
    "print(f\"\\nðŸ” Fetching available trading pairs from {CONFIG['trading_connector']}...\")\n",
    "trading_rules = await clob.get_trading_rules(CONFIG['trading_connector'])\n",
    "\n",
    "# Try different quote assets to find available pairs\n",
    "quote_assets_to_try = [\"USD\", \"USDT\"]\n",
    "available_trading_pairs = set()\n",
    "\n",
    "for quote_asset in quote_assets_to_try:\n",
    "    try:\n",
    "        pairs = trading_rules.filter_by_quote_asset(quote_asset).get_all_trading_pairs()\n",
    "        if pairs:\n",
    "            available_trading_pairs.update(pairs)\n",
    "            print(f\"   Found {len(pairs)} pairs with quote asset {quote_asset}\")\n",
    "    except Exception as e:\n",
    "        pass  # Skip if quote asset doesn't exist\n",
    "\n",
    "if not available_trading_pairs:\n",
    "    # Fallback: get all trading pairs regardless of quote asset\n",
    "    all_pairs = trading_rules.get_all_trading_pairs()\n",
    "    available_trading_pairs = set(all_pairs)\n",
    "    print(f\"   Using all {len(all_pairs)} trading pairs (no quote asset filter)\")\n",
    "\n",
    "print(f\"âœ… Found {len(available_trading_pairs)} total trading pairs on {CONFIG['trading_connector']}\")\n",
    "\n",
    "# Extract base tokens from trading connector pairs\n",
    "# This allows comparison regardless of quote asset (USD vs USDT)\n",
    "available_base_tokens = {extract_base_token(pair) for pair in available_trading_pairs}\n",
    "print(f\"   Unique base tokens: {len(available_base_tokens)}\")\n",
    "\n",
    "# Filter candles to only include pairs available on the trading connector\n",
    "# Compare based on base tokens only (ignores quote asset differences)\n",
    "print(f\"\\nðŸ”Ž Filtering candles to only include pairs available on {CONFIG['trading_connector']}...\")\n",
    "print(f\"   Comparing base tokens only (handles USD vs USDT differences)\")\n",
    "filtered_candles = []\n",
    "filtered_out_count = 0\n",
    "\n",
    "for candle in candles:\n",
    "    candle_base_token = extract_base_token(candle.trading_pair)\n",
    "    if candle_base_token in available_base_tokens:\n",
    "        filtered_candles.append(candle)\n",
    "    else:\n",
    "        filtered_out_count += 1\n",
    "\n",
    "candles = filtered_candles  # Replace with filtered list\n",
    "\n",
    "print(f\"âœ… Filtered results:\")\n",
    "print(f\"   â€¢ Pairs before filtering: {len(filtered_candles) + filtered_out_count}\")\n",
    "print(f\"   â€¢ Pairs after filtering: {len(candles)}\")\n",
    "print(f\"   â€¢ Filtered out: {filtered_out_count}\")\n",
    "print(f\"\\nðŸ“Š Will generate features and signals for {len(candles)} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ot7qo4d9pi",
   "metadata": {},
   "source": [
    "## Improved Feature Engineering System\n",
    "\n",
    "Using the streamlined feature engineering system with:\n",
    "- **One feature per strategy/calculation** (not per indicator)\n",
    "- Flexible value types: float, List[float], or Dict[str, float]\n",
    "- MongoDB-only storage for production use\n",
    "- Standardized signal model with -1 to 1 scale\n",
    "- Type-safe Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hiota8m4d4l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new feature engineering system\n",
    "from core.features import FeatureStorage, Feature, Signal\n",
    "from core.features.candles.ema_trend import EMATrend, EMATrendConfig\n",
    "\n",
    "# Initialize feature storage (MongoDB only)\n",
    "storage = FeatureStorage()\n",
    "await storage.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p56chh7dk6o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EMA trend feature calculator\n",
    "ema_config = EMATrendConfig(\n",
    "    ema_lengths=CONFIG['ema_lengths'],\n",
    "    rolling_window=CONFIG['rolling_window']\n",
    ")\n",
    "\n",
    "ema_trend = EMATrend(feature_config=ema_config)\n",
    "\n",
    "print(f\"âœ… Initialized EMA Trend feature calculator\")\n",
    "print(f\"   EMA lengths: {ema_config.ema_lengths}\")\n",
    "print(f\"   Rolling window: {ema_config.rolling_window}\")\n",
    "print(f\"\\nðŸ“Š This creates ONE feature per pair containing all EMA trend data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nfohtzafuw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features and signals using the improved system\n",
    "all_features = []\n",
    "all_signals = []\n",
    "\n",
    "signals_for_display = []\n",
    "\n",
    "for candle in candles:\n",
    "    try:\n",
    "        # Pass the Candles object directly - much cleaner!\n",
    "        feature = ema_trend.create_feature(candle)\n",
    "        all_features.append(feature)\n",
    "        \n",
    "        # Create signal if criteria met\n",
    "        signal = ema_trend.create_signal(\n",
    "            candle,\n",
    "            min_intensity=CONFIG['signal_intensity_threshold'],\n",
    "            min_range_pct=CONFIG['min_range_pct']\n",
    "        )\n",
    "        \n",
    "        if signal:\n",
    "            all_signals.append(signal)\n",
    "            \n",
    "            # Collect for reporting (signal.value ranges from -1 to 1)\n",
    "            signals_for_display.append({\n",
    "                'trading_pair': signal.trading_pair,\n",
    "                'category': signal.category,\n",
    "                'signal_value': signal.value,\n",
    "                'direction': 'LONG' if signal.value > 0 else 'SHORT',\n",
    "                'intensity': abs(signal.value),\n",
    "                'range_pct': feature.value['range_pct'],\n",
    "                'ema_divergence': feature.value['divergence']\n",
    "            })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {candle.trading_pair}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Processed {len(candles)} pairs\")\n",
    "print(f\"ðŸ“Š Generated {len(all_features)} features (1 per pair)\")\n",
    "print(f\"ðŸŽ¯ Generated {len(all_signals)} signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4yqbg11vs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Show what a single feature looks like\n",
    "if len(candles) > 0:\n",
    "    example_candle = candles[0]\n",
    "    \n",
    "    # Now we just pass the Candles object - it contains everything!\n",
    "    example_feature = ema_trend.create_feature(example_candle)\n",
    "    \n",
    "    print(f\"ðŸ“ Example Feature for {example_feature.trading_pair}:\")\n",
    "    print(f\"   Feature name: {example_feature.feature_name}\")\n",
    "    print(f\"   Connector: {example_feature.connector_name}\")\n",
    "    print(f\"   Timestamp: {example_feature.timestamp}\")\n",
    "    print(f\"\\n   Value (dict with all EMA trend data):\")\n",
    "    for key, val in example_feature.value.items():\n",
    "        if isinstance(val, float):\n",
    "            print(f\"     â€¢ {key}: {val:.6f}\")\n",
    "        else:\n",
    "            print(f\"     â€¢ {key}: {val}\")\n",
    "    \n",
    "    print(f\"\\n   Info (metadata):\")\n",
    "    for key, val in example_feature.info.items():\n",
    "        print(f\"     â€¢ {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rkuekbybho",
   "metadata": {},
   "source": [
    "### Visualize Feature\n",
    "\n",
    "Features now have built-in visualization methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urdxswbh5hp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the feature on candlestick chart\n",
    "if len(candles) > 0:\n",
    "    example_candle = candles[0]\n",
    "    \n",
    "    # The feature can plot itself!\n",
    "    print(f\"ðŸ“ˆ Plotting {example_candle.trading_pair} with EMA Trend feature...\")\n",
    "    ema_trend.plot(example_candle, height=600, width=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fzk7cm195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or manually add to an existing figure\n",
    "if len(candles) > 0:\n",
    "    example_candle = candles[0]\n",
    "    \n",
    "    # Start with candles\n",
    "    fig = example_candle.candles_fig(height=600, width=1400)\n",
    "    \n",
    "    # Add the EMA trend feature\n",
    "    fig = ema_trend.add_to_fig(fig, example_candle)\n",
    "    \n",
    "    # Could add more features here...\n",
    "    # fig = another_feature.add_to_fig(fig, example_candle)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0tva1z7wup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features and signals to MongoDB\n",
    "print(\"Saving features and signals to MongoDB...\")\n",
    "\n",
    "# Save features\n",
    "await storage.save_features(all_features)\n",
    "\n",
    "# Save signals\n",
    "await storage.save_signals(all_signals)\n",
    "\n",
    "print(f\"âœ… Saved {len(all_features)} features\")\n",
    "print(f\"âœ… Saved {len(all_signals)} signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37qtcnn8bmx",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display signals in DataFrame format\n",
    "signals_df = pd.DataFrame(signals_for_display).sort_values(by='intensity', ascending=False)\n",
    "\n",
    "print(f\"Total signals: {len(signals_df)}\")\n",
    "print(f\"Long signals: {len(signals_df[signals_df['direction'] == 'LONG'])}\")\n",
    "print(f\"Short signals: {len(signals_df[signals_df['direction'] == 'SHORT'])}\")\n",
    "\n",
    "# Show top signals\n",
    "print(\"\\\\nTop 10 Signals:\")\n",
    "display(signals_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0rsr3clehzj",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ggi6xs223rn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nðŸ“Š Data Processing:\")\n",
    "print(f\"   â€¢ Pairs processed: {len(candles)}\")\n",
    "print(f\"   â€¢ Features generated: {len(all_features)} (1 per pair)\")\n",
    "print(f\"   â€¢ Signals generated: {len(all_signals)}\")\n",
    "\n",
    "if len(signals_df) > 0:\n",
    "    print(f\"\\nðŸŽ¯ Signal Breakdown:\")\n",
    "    print(f\"   â€¢ Long signals (value > 0): {len(signals_df[signals_df['direction'] == 'LONG'])}\")\n",
    "    print(f\"   â€¢ Short signals (value < 0): {len(signals_df[signals_df['direction'] == 'SHORT'])}\")\n",
    "    print(f\"   â€¢ Average intensity: {signals_df['intensity'].mean():.3f}\")\n",
    "    print(f\"   â€¢ Max intensity: {signals_df['intensity'].max():.3f}\")\n",
    "    \n",
    "print(f\"\\nðŸ’¾ Storage:\")\n",
    "print(f\"   â€¢ Features saved to MongoDB: {len(all_features)}\")\n",
    "print(f\"   â€¢ Signals saved to MongoDB: {len(all_signals)}\")\n",
    "print(f\"   â€¢ Collection: 'features' and 'signals'\")\n",
    "\n",
    "print(f\"\\nâœ… Efficiency Gain:\")\n",
    "old_approach = len(candles) * 5  # 5 features per pair in old approach\n",
    "new_approach = len(all_features)  # 1 feature per pair\n",
    "reduction = ((old_approach - new_approach) / old_approach * 100) if old_approach > 0 else 0\n",
    "print(f\"   â€¢ Old approach would create: ~{old_approach} documents\")\n",
    "print(f\"   â€¢ New approach creates: {new_approach} documents\")\n",
    "print(f\"   â€¢ Reduction: {reduction:.0f}%\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8du5jynn166",
   "metadata": {},
   "source": [
    "## Query Stored Features and Signals\n",
    "\n",
    "Demonstrate retrieving features and signals from storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osv3xmv8y1",
   "metadata": {},
   "source": [
    "## Use Signals for Trading\n",
    "\n",
    "Now that we have signals, let's prepare them for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1lgjhlaemlp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top signals for trading\n",
    "top_long_signals = signals_df[signals_df['direction'] == 'LONG'].head(3)\n",
    "top_short_signals = signals_df[signals_df['direction'] == 'SHORT'].head(3)\n",
    "\n",
    "print(\"ðŸŸ¢ Top 3 Long Signals for Trading:\")\n",
    "display(top_long_signals)\n",
    "\n",
    "print(\"\\nðŸ”´ Top 3 Short Signals for Trading:\")\n",
    "display(top_short_signals)\n",
    "\n",
    "# For each signal, we can get the full feature data from storage\n",
    "if len(top_long_signals) > 0:\n",
    "    example_pair = top_long_signals.iloc[0]['trading_pair']\n",
    "    \n",
    "    # Get the feature to access grid levels\n",
    "    pair_features = await storage.get_features(\n",
    "        feature_name=\"ema_trend\",\n",
    "        trading_pair=example_pair,\n",
    "        connector_name=CONFIG['connector_name'],\n",
    "        limit=1\n",
    "    )\n",
    "    \n",
    "    if pair_features:\n",
    "        feat = pair_features[0]\n",
    "        range_pct = feat.value['range_pct']\n",
    "        price = feat.value['price']\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ Example Grid Levels for {example_pair}:\")\n",
    "        print(f\"   Current Price: ${price:.6f}\")\n",
    "        print(f\"   Range %: {range_pct*100:.2f}%\")\n",
    "        \n",
    "        # Calculate grid levels (same logic as before)\n",
    "        start_price = price * (1 - 0.5 * range_pct)\n",
    "        end_price = price * (1 + 1.5 * range_pct)\n",
    "        limit_price = price * (1 - 0.7 * range_pct)\n",
    "        \n",
    "        print(f\"   Start Price: ${start_price:.6f}\")\n",
    "        print(f\"   End Price: ${end_price:.6f}\")\n",
    "        print(f\"   Limit Price: ${limit_price:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64i2k31vbvp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query recent high-intensity long signals (value > 0.8)\n",
    "recent_long_signals = await storage.get_signals(\n",
    "    category='tf',  # trend following\n",
    "    min_value=0.8,  # Strong long signals\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(recent_long_signals)} high-intensity long signals:\")\n",
    "for sig in recent_long_signals:\n",
    "    print(f\"  {sig.trading_pair}: value={sig.value:.3f} ({sig.signal_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rm2pn1o4gn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query features for a specific trading pair\n",
    "example_pair = signals_for_display[0]['trading_pair'] if signals_for_display else \"BTC-USDT\"\n",
    "\n",
    "features_for_pair = await storage.get_features(\n",
    "    feature_name=\"ema_trend\",\n",
    "    trading_pair=example_pair,\n",
    "    connector_name=CONFIG['connector_name'],\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "if features_for_pair:\n",
    "    feat = features_for_pair[0]\n",
    "    print(f\"EMA Trend feature for {example_pair}:\")\n",
    "    print(f\"  Timestamp: {feat.timestamp}\")\n",
    "    print(f\"\\\\n  Values:\")\n",
    "    for key, val in feat.value.items():\n",
    "        if isinstance(val, float):\n",
    "            print(f\"    {key}: {val:.6f}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {val}\")\n",
    "    if feat.info:\n",
    "        print(f\"\\\\n  Info:\")\n",
    "        for key, val in feat.info.items():\n",
    "            print(f\"    {key}: {val}\")\n",
    "else:\n",
    "    print(f\"No features found for {example_pair}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quants-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
